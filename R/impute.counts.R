#' @title impute.counts
#'
#' @description Function that allows for the imputation of missing values using 4 possible algorithms: \href{https://www.rdocumentation.org/packages/missForest/}{missForest}, \href{https://rdrr.io/cran/VIM/man/kNN.html}{kNN}, \href{https://rdrr.io/bioc/pcaMethods/man/llsImpute.html}{LLS}, \href{https://rdrr.io/bioc/pcaMethods/man/pca.html}{SVD}.
#'
#' @param DEprot.object A \code{DEprot object}, as generated by \link{load.counts}.
#' @param method String indicating the imputation method to use. One among: 'missForest', 'kNN' (VIM), 'tkNN' (imputomics), 'corkNN' (imputomics), 'LLS' (pcaMethods), 'SVD' (a.k.a svdImpute, pcaMethods), 'BPCA' (pcaMethods), 'PPCA' (pcaMethods), 'RegImpute' (DreamAI). Default: \code{"missForest"}.
#' @param use.normalized.data Logical value indicating whether the imputation should be performed based on the rationalized data. Default: \code{TRUE}.
#' @param overwrite.imputation Logical value to indicate whether, in the case already available, the table of imputed counts should be overwritten. Default: \code{FALSE}.
#' @param missForest.max.iterations Max number of iterations for the missForest algorithm. Default: \code{100}.
#' @param missForest.variable.wise.OOBerror Logical value to define whether the OOB error is returned for each variable separately. Default: \code{TRUE}.
#' @param missForest.cores Number of cores used to run the \code{missForest} algorithm. If \code{missForest.cores} is 1 (or lower), the imputation will be run in parallel. Two modes are possible and can be defined by the parameter \code{missForest.parallel.mode}. Default: \code{1}.
#' @param missForest.parallel.mode Define the mode to use for the parallelization, ignored when \code{cores} is more than 1. One among: 'variables', 'forests'. Default: \code{"variables"}. See also the documentation of the \href{https://www.rdocumentation.org/packages/missForest/versions/1.5/topics/missForest}{missForest function}.
#' @param kNN.n.nearest.neighbours Numeric value indicating the number of nearest neighbors to use to perform the \code{kNN} imputation. Default: \code{10}.
#' @param LLS.k Cluster size, this is the number of similar genes used for regression. Default: \code{2}.
#' @param pcaMethods.nPCs.to.test Numeric value indicating the number of Principal Components to test in order to find the optimal number of PCs to used in the imputation methods from the \code{pcaMethods} package. This includes: 'LLS', 'SVD' (a.k.a 'svdImpute'), 'BPCA-pcaMethods', and 'PPCA'. Default: \code{5}.
#' @param RegImpute.max.iterations Numeric value indicating the number of maximum iteration for the imputation with \code{RegImpute} (from \code{DreamAI}). Default: \code{10}.
#' @param RegImpute.fillmethod String identifying the fill method to be used in the \code{RegImpute} method (from\code{DreamAI}). One among \code{"row_mean"} and \code{"zeros"}. Default: \code{"row_mean"}. It throws an warning if \code{"row_median"} is used.
#' @param verbose Logical valued indicating whether processing messages should be printed. Default: \code{FALSE}.
#'
#' @seealso \href{https://www.rdocumentation.org/packages/missForest/}{missForest}, \href{https://cran.r-project.org/web/packages/VIM/index.html}{VIM}, \href{https://www.bioconductor.org/packages/release/bioc/html/pcaMethods.html}{pcaMethods} R-packages, \href{https://github.com/sebastian-gregoricchio/DreamAI/}{DreamAI}, \href{https://github.com/BioGenies/imputomics}{imputomics}.
#'
#' @return A \code{DEprot} object. The boxplot showing the distribution of the protein intensity is remade and added to the slot (\code{boxplot.imputed}). A list with parameters and other info about the imputation is added as well in the \code{imputation} slot.
#'
#' @import dplyr
#' @import ggplot2
#' @import missForest
#' @importFrom VIM kNN
#' @import laeken
#' @import pcaMethods
#' @importFrom reshape2 melt
#' @import ggtext
#' @import doRNG
#' @importFrom doParallel registerDoParallel
#' @importFrom reshape2 melt
#' @importFrom foreach foreach
#' @importFrom ggpubr theme_pubr
#' @importFrom glmnet cv.glmnet
#'
#' @author Sebastian Gregoricchio
#'
#' @export impute.counts


impute.counts =
  function(DEprot.object,
           method = "missForest",
           use.normalized.data = TRUE,
           overwrite.imputation = FALSE,
           missForest.max.iterations = 100,
           missForest.variable.wise.OOBerror = TRUE,
           missForest.cores = 1,
           missForest.parallel.mode = "variables",
           kNN.n.nearest.neighbours = 10,
           LLS.k = 2,
           pcaMethods.nPCs.to.test = 5,
           RegImpute.max.iterations = 10,
           RegImpute.fillmethod = "row_mean",
           verbose = FALSE) {

    # ### Libraries
    # require(dplyr)
    # require(ggplot2)
    `%dorng%` <- doRNG::`%dorng%`


    ### check object
    if (!("DEprot" %in% class(DEprot.object))) {
      stop("The input must be an object of class 'DEprot'.")
      #return(DEprot.object)
    }



    ### Check if imputation already available
    if (DEprot.object@imputed == TRUE) {
      if (overwrite.imputation == FALSE) {
        stop(paste0("The 'DEprot' object contains already an imputed table.\n",
                    "       If you wish to overwrite the imputation, set the parameter `overwrite.imputation = TRUE`."))
        #return(DEprot.object)
      }
    }


    ### Check if normalized data are available
    if (use.normalized.data == TRUE) {
      if (is.null(DEprot.object@norm.counts)) {
        stop(paste0("You asked to use normalized data for the imputation, but normalized data are not available.\n",
                    "       To perform imputation on raw data, set `use.normalized.data = FALSE`."))
        #return(DEprot.object)
      } else {
        cnt = DEprot.object@norm.counts
      }
    } else {
      cnt = DEprot.object@raw.counts
    }


    ### Check imputation method
    if (!(tolower(method) %in% tolower(c("missForest", "KNN", "kNN-VIM", "tKNN", "corkNN", "SVD", "svd-pcamethods", "svdimpute", "svdimpute-pcamethods", "LLS", "LLS-pcaMethods", "BPCA-pcaMethods", "BPCA", "PPCA", "ppca-pcamethods", "RegImpute", "regimpute-dreamAI")))) {
      stop("The imputation 'method' must be one among: missForest, KNN, tKNN, corkNN, SVD, LLS, BPCA, PPCA, RegImpute.")
      #return(DEprot.object)
    }



    ######################################################################################
    ## EXTERNAL FUNCTIONS
    ### From imputomics: see https://github.com/BioGenies/imputomics/blob/6943055e14277596fb2a3030ef94dfed46beaefd/R/Trunc_KNN.R#L238

    EstimatesComputation <-
      function(missingdata,
               perc,
               iter=50) {

        ## 2 column matrix where column 1 = means, column 2 = SD
        ParamEstim <- matrix(NA, nrow = nrow(missingdata), ncol = 2)
        nsamp <- ncol(missingdata)

        ## sample means / SDs
        ParamEstim[,1] <- rowMeans(missingdata, na.rm = TRUE)
        ParamEstim[,2] <- apply(missingdata, 1, function(x) sd(x, na.rm = TRUE))

        ## Case 1: missing % > perc => use sample mean / SD
        na.sum <- apply(missingdata, 1, function(x) sum(is.na(x)))
        idx1 <- which(na.sum/nsamp >= perc)

        ## Case 2: sample mean > 3 SD away from LOD => use sample mean / SD
        lod <- min(missingdata, na.rm=TRUE) ## why use the min of whole data set??????
        idx2 <- which(ParamEstim[,1] > 3*ParamEstim[,2] + lod)

        ## Case 3: for all others, use NR method to obtain truncated mean / SD estimate
        idx.nr <- setdiff(1:nrow(missingdata), c(idx1, idx2))
        ## t = limits of integration (LOD and upper)
        upplim <- max(missingdata, na.rm=TRUE) + 2*max(ParamEstim[,2])
        for (i in idx.nr) {
          Likelihood <- mklhood(missingdata[i,], t=c(lod, upplim))
          res <- tryCatch(NewtonRaphsonLike(Likelihood, p = ParamEstim[i,]),
                          error = function(e) 1000)

          if (length(res) == 1) {
            next
          } else if (res$iter >= iter) {
            next
          } else {
            ParamEstim[i,] <- as.numeric(res$estimate)
          }
        }
        return(ParamEstim)
      }



    mklhood <- function(data, t, ...) {

      data <- na.omit(data)
      n <- length(data)
      t <- sort(t)

      psi<-function(y, mu, sigma){
        exp(-(y-mu)^2/(2*sigma^2))/(sigma*sqrt(2*pi))
      }

      psi.mu<-function(y,mu,sigma){
        exp(-(y-mu)^2/(2*sigma^2)) * ((y-mu)/(sigma^3*sqrt(2*pi)))
      }

      psi.sigma<-function(y,mu,sigma){
        exp(-(y-mu)^2/(2*sigma^2)) *
          (((y-mu)^2)/(sigma^4*sqrt(2*pi)) - 1/(sigma^2*sqrt(2*pi)))
      }

      psi2.mu<-function(y,mu,sigma){
        exp(-(y - mu)^2/(2*sigma^2)) *
          (((y - mu)^2)/(sigma^5*sqrt(2*pi))-1/(sigma^3*sqrt(2*pi)))
      }

      psi2.sigma<-function(y,mu,sigma){
        exp(-(y-mu)^2/(2*sigma^2)) *
          ((2)/(sigma^3*sqrt(2*pi)) - (5*(y-mu))/(sigma^5*sqrt(2*pi)) +
             ((y-mu)^4)/(sigma^7*sqrt(2*pi)))
      }

      psi12.musig<-function(y,mu,sigma){
        exp(-(y-mu)^2/(2*sigma^2)) *
          (((y-mu)^3)/(sigma^6*sqrt(2*pi)) - (3*(y-mu))/(sigma^4*sqrt(2*pi)))
      }

      ll.tnorm2<-function(p){
        out <- (-n*log(pnorm(t[2],p[1],p[2])-pnorm(t[1],p[1],p[2]))) -
          (n*log(sqrt(2*pi*p[2]^2))) - (sum((data-p[1])^2)/(2*p[2]^2))
        -1*out
      }

      grad.tnorm<-function(p){
        g1 <- (-n*(integrate(psi.mu,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value) /
                 (pnorm(max(t),p[1],p[2])-pnorm(min(t),p[1],p[2]))) - ((n*p[1]-sum(data))/p[2]^2)
        g2 <- (-n*(integrate(psi.sigma,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value) /
                 (pnorm(max(t),p[1],p[2])-pnorm(min(t),p[1],p[2]))) - ((n)/(p[2])) + ((sum((data-p[1])^2))/(p[2]^3))
        out <- c(g1,g2)
        return(out)
      }

      hessian.tnorm<-function(p){

        h1<- -n*(integrate(psi,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value *
                   integrate(psi2.mu,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value -
                   integrate(psi.mu,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value^2) /
          (integrate(psi,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value^2) -
          n/(p[2]^2)

        h3<- -n*(integrate(psi,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value *
                   integrate(psi12.musig,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value -
                   integrate(psi.mu,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value *
                   integrate(psi.sigma,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value) /
          (integrate(psi,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value^2) +
          (2*(n*p[1]-sum(data)))/(p[2]^3)

        h2<- -n*(integrate(psi,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value *
                   integrate(psi2.sigma,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value -
                   integrate(psi.sigma,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value^2) /
          (integrate(psi,t[1],t[2],mu=p[1],sigma=p[2], stop.on.error = FALSE)$value^2) +
          (n)/(p[2]^2)-(3*sum((data-p[1])^2))/(p[2]^4)

        H<-matrix(0,nrow=2,ncol=2)
        H[1,1]<-h1
        H[2,2]<-h2
        H[1,2]<-H[2,1]<-h3
        return(H)
      }

      return(list(ll.tnorm2 = ll.tnorm2,
                  grad.tnorm = grad.tnorm,
                  hessian.tnorm = hessian.tnorm))
    }



    imputeKNN <-
      function (data,
                k = ceiling(nrow(data)*0.05) + 1,
                distance = "truncation",
                rm.na = TRUE,
                rm.nan = TRUE,
                rm.inf = TRUE,
                perc=1,
                ...) {

        if (!(is.matrix(data))) {
          stop(message = paste(deparse(substitute(data)),
                               " is not a matrix.", sep = ""))
        }

        distance <- match.arg(distance, c("correlation","truncation"))

        nr <- dim(data)[1]
        if (k < 1 | k > nr) {
          stop(message = "k should be between 1 and the number of rows")
        }

        if (distance=="correlation"){
          genemeans<-rowMeans(data,na.rm=TRUE)
          genesd<-apply(data, 1, function(x) sd(x, na.rm = TRUE))
          data<-(data-genemeans)/genesd
        }

        if (distance=="truncation"){


          ParamMat <- EstimatesComputation(data, perc = perc)

          genemeans<-ParamMat[,1]
          genesd<-ParamMat[,2]
          data<-(data-genemeans)/genesd
        }

        imp.knn <- data
        imp.knn[is.finite(data) == FALSE] <- NA
        t.data<-t(data)

        mv.ind <- which(is.na(imp.knn), arr.ind = TRUE)
        arrays <- unique(mv.ind[, 2])
        array.ind <- match(arrays, mv.ind[, 2])
        ngenes <- 1:nr

        for (i in 1:length(arrays)) {
          set <- array.ind[i]:min((array.ind[(i + 1)] - 1), dim(mv.ind)[1],
                                  na.rm = TRUE)
          cand.genes <- ngenes[-unique(mv.ind[set, 1])]
          cand.vectors <- t.data[,cand.genes]
          exp.num<- arrays[i]
          for (j in set) {

            gene.num <- mv.ind[j, 1]
            tar.vector <- data[gene.num,]

            r <- (cor(cand.vectors,tar.vector, use = "pairwise.complete.obs"))
            dist <- switch(distance,
                           correlation = (1 - abs(r)),
                           truncation = (1 - abs(r)))
            dist[is.nan(dist) | is.na(dist)] <- Inf
            dist[dist==0]<-ifelse(is.finite(min(dist[dist>0])), min(dist[dist>0])/2, 1)
            dist[abs(r) == 1] <- Inf

            if (sum(is.finite(dist)) < k) {
              stop(message = "Fewer than K finite distances found")
            }
            k.genes.ind <- order(dist)[1:k]
            k.genes <- cand.genes[k.genes.ind]

            wghts <- (1/dist[k.genes.ind]/sum(1/dist[k.genes.ind])) * sign(r[k.genes.ind])
            imp.knn[gene.num, exp.num] <- wghts %*% data[k.genes, exp.num]
          }
        }

        if (distance=="correlation") {
          imp.knn <- (imp.knn * genesd) + genemeans
        }

        if(distance=="truncation") {
          imp.knn <- (imp.knn * genesd) + genemeans
        }

        if (!rm.na) {
          imp.knn[is.na(data) == TRUE & is.nan(data) == FALSE] <- NA
        }
        if (!rm.inf) {
          index <- is.finite(data) == FALSE & is.na(data) == FALSE &
            is.nan(data) == FALSE
          imp.knn[index] <- data[index]
        }
        if (!rm.nan) {
          imp.knn[is.nan(data) == TRUE] <- NaN
        }
        return(imp.knn)
      }

    # ------------------------------------------------------------------------------------
    # from DreamAI
    # see https://github.com/sebastian-gregoricchio/DreamAI/blob/master/Code/R/RegImpute.R

    backfill <- function(data,fillmethod=fillmethod){

      if ((fillmethod!="zeros") & (fillmethod!="row_mean")) {
        stop("Accepted Fill Methods Include \"zeros\",\"row_mean\"", call.=FALSE)
      }

      print(paste("Back Filling With Method: ",fillmethod))

      if(fillmethod == "zeros"){
        missing_indices = which(is.na(data), arr.ind=TRUE)
        data[missing_indices] = 0
      }
      if(fillmethod == "row_mean"){
        ind <- which(is.na(data), arr.ind=TRUE)
        data[ind] <- rowMeans(data,  na.rm = TRUE)[ind[,1]]
      }

      return(data)
    }


    returnPresentIndices<-function(col,data,filled){
      #Indices @ current column, only where values aren't missing
      present_indices = which(!is.na(data[,col]), arr.ind=TRUE)
      return(present_indices)
    }


    returnTrainingSet<-function(col,filled,present_indices){
      #Only rows where value is present at current column.  All columns except for current.
      train = filled[,-col][present_indices,]
      return(train)
    }


    returnTargets<-function(col,data,present_indices){
      #Current column, only indices where values were present in original data
      target = data[present_indices,col]
      return(target)
    }


    returnTestIndices<-function(col,data){
      #Indices @ current column, only where values are missing
      test_indices = which(is.na(data[,col]), arr.ind=TRUE)
      return(test_indices)
    }


    returnTestSet<-function(col,filled,test_indices){
      test = filled[,-col][test_indices,]
      return(test)
    }

    impute.RegImpute <- function(data,fillmethod,maxiter_RegImpute,conv_nrmse){
      filled = backfill(data,fillmethod)
      print(paste("Starting Imputation With ",toString(maxiter_RegImpute)," Max. Iterations"))
      missing_indices = which(is.na(data), arr.ind=TRUE)


      #Begin iterative imputation.  Missing value slots in data are updated on each iteration
      for(i in 1:maxiter_RegImpute){
        print(paste("Working on Iteration: ",toString(i),"/",toString(maxiter_RegImpute)))


        #Iterate over columns
        for(col in 1:dim(data)[2]){

          if(sum(is.na(data[,col]))==0){next} #continue if there aren't any missing values in the current column

          #otherwise, begin imputation
          present_indices = returnPresentIndices(col,data,filled)
          train = returnTrainingSet(col,filled,present_indices)
          target = returnTargets(col,data,present_indices)
          test_indices = returnTestIndices(col,data)
          test = returnTestSet(col,filled,test_indices)

          #used http://ricardoscr.github.io/how-to-use-ridge-and-lasso-in-r.html as tutorial on ridge regression in R
          cv_fit <- glmnet::cv.glmnet(train, target, alpha=0, standardize=TRUE)
          opt_lambda = cv_fit$lambda.min
          fit = cv_fit$glmnet.fit

          test<-as.matrix(test)
          if(dim(test)[2]==1)
          {
            predicted = predict(fit, s = opt_lambda, newx=t(test))
          }else{
            predicted = predict(fit, s = opt_lambda, newx=test)
          }
          filled[test_indices,col] = predicted
        }

        #test for convergence at each iteration
        if(i==1){
          impvals = filled[missing_indices]
        }
        else{
          NRMSE = sqrt(mean((impvals - filled[missing_indices])^2))
          print(paste("NRMSE = ",NRMSE))
          impvals = filled[missing_indices]
          if (NRMSE<conv_nrmse){
            return(filled)
          }
        }
      }
      return(filled)
    }

    ######################################################################################
    ## INTERNAL FUNCTIONS
    estimate.PCs =
      function(mat, method, nPcs) {
        # Cross-validation results
        cv_res = pcaMethods::pca(mat, method=method, nPcs=nPcs, scale="uv", validation="MSEP", verbose=FALSE)
        Q2_PCs = pcaMethods::Q2(cv_res, verbose=FALSE) # where Q2 is the cross-validated variance explained
        optimal_nPcs = unname(which.max(Q2_PCs))

        cross.validation.plot =
          ggplot(data = data.frame(Q2_cv = Q2_PCs,
                                   PCs = 1:length(Q2_PCs)),
                 aes(x = PCs,
                     y = Q2_PCs)) +
          geom_vline(xintercept = optimal_nPcs, color = "firebrick", linetype = 3) +
          geom_line(linewidth = 1, color = "navy") +
          geom_point(shape = 21, fill = "white", size = 3) +
          ylab("Q<sup>2</sup>(Cross-Validation)") +
          xlab("Number of PCs") +
          ggtitle("**Cross-validated variance explained**",
                  subtitle = paste(toupper(method), "[pcaMethods]")) +
          ggpubr::theme_pubr() +
          theme(plot.title = ggtext::element_markdown(hjust = 0.5),
                plot.subtitle = ggtext::element_markdown(hjust = 0.5),
                axis.title = ggtext::element_markdown(hjust = 0.5))

        return(list(cross.validation.results = cv_res,
                    Q2.PCs = Q2_PCs,
                    optimal.nPcs = optimal_nPcs,
                    cross.validation.plot = cross.validation.plot))
      }


    ######################################################################################

    if (tolower(method) == "missforest") {
      # require(doParallel)
      # require(doRNG)

      ### Check whether there are at least 3 known values per each protein in the counts table (otherwise miss Forest cannot compute)
      n.present.values = rowSums(!is.na(cnt))

      if (TRUE %in% (n.present.values < 3)) {
        stop(paste0("The following proteins display less than 3 known values; this might break the `missForest` imputation:\n",
                    paste0(names(n.present.values[n.present.values < 3]), collapse = ", "),"."))
      }

      ### Run missForest algorithm
      # Parallelize if required
      start.time = Sys.time()

      cores = ifelse(test = missForest.cores > 1, yes = min(c(missForest.cores, nrow(cnt))), no = 1)
      doParallel::registerDoParallel(cores = cores)
      #getDoParWorkers()
      doRNG::registerDoRNG(seed = 1.618)
      DoRNG.check = try(invisible(foreach::foreach(i=1:3) %dorng% sqrt(i)))


      if (!("list" %in% class(DoRNG.check)) | cores <= 1) {
        imputed.cnt = missForest::missForest(xmis = t(cnt), maxiter = missForest.max.iterations, verbose = verbose, variablewise = missForest.variable.wise.OOBerror, parallelize = "no")
      } else {
        if (tolower(missForest.parallel.mode) %in% c("variables", "forests")) {
          imputed.cnt = missForest::missForest(xmis = t(cnt), maxiter = missForest.max.iterations, verbose = verbose, variablewise = missForest.variable.wise.OOBerror, parallelize = tolower(missForest.parallel.mode))
        } else {
          stop(paste0("The missForest.parallel.mode must be one among: 'variables', 'forests'."))
          #return(DEprot.object)
        }
      }

      if (missForest.variable.wise.OOBerror == TRUE) {
        names(imputed.cnt$OOBerror) = colnames(t(cnt))
      }

      end.time = Sys.time()
      time.taken = round(end.time - start.time,2)


      ## Define imputation method list
      imputation = list(method = "missForest",
                        max.iterations = missForest.max.iterations,
                        OOBerror = imputed.cnt$OOBerror,
                        parallelization.mode = ifelse(cores <=1, yes = "none", no = missForest.parallel.mode),
                        cores = cores,
                        processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))

      imputed.cnt = imputed.cnt$ximp

      ####################################################################################

    } else if (tolower(method) %in% c("knn", "knn-vim")) {
      start.time = Sys.time()

      imputed.cnt = VIM::kNN(data = t(cnt), numFun = laeken::weightedMean, weightDist = TRUE, imp_var = FALSE, k = kNN.n.nearest.neighbours)
      rownames(imputed.cnt) = colnames(cnt)

      end.time = Sys.time()
      time.taken = round(end.time - start.time,2)

      ## Define imputation method list
      imputation = list(method = "kNN",
                        aggregating.function = "weighted mean",
                        n.nearest.neighbours = kNN.n.nearest.neighbours,
                        processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))

      ####################################################################################

    } else if (tolower(method) %in% c("lls", "lls-pcamethods")) {
      start.time = Sys.time()

      imputed.cnt = (pcaMethods::llsImpute(Matrix = t(cnt), k = LLS.k, correlation = "pearson", allVariables = TRUE, verbose = verbose))@completeObs

      end.time = Sys.time()
      time.taken = round(end.time - start.time,2)

      ## Define imputation method list
      imputation = list(method = "LLS",
                        aggregating.function = "weighted mean",
                        cluster.size = LLS.k,
                        correlation.type = "pearson",
                        processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))

      #########################################################################################

    } else if (tolower(method) %in% c("svd", "svd-pcamethods", "svdimpute", "svdimpute-pcamethods")) {
      start.time = Sys.time()

      PC.estimation = estimate.PCs(mat = t(cnt), method = "svdImpute", nPcs = pcaMethods.nPCs.to.test)
      imputed.cnt = (pcaMethods::pca(object = t(cnt), method = "svdImpute", nPcs = PC.estimation$optimal.nPcs, verbose = verbose))@completeObs

      end.time = Sys.time()
      time.taken = round(end.time - start.time,2)

      ## Define imputation method list
      imputation = list(method = "SVD",
                        PC.estimation = PC.estimation,
                        processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))

      #########################################################################################
    } else if (tolower(method) == "tknn") {

      start.time = Sys.time()

      imputed.cnt = t(suppressWarnings(imputeKNN(as.matrix(cnt), k = ceiling(nrow(cnt)*0.05) + 1, distance = "truncation", rm.na = TRUE, rm.nan = FALSE, rm.inf = FALSE)))

      end.time = Sys.time()
      time.taken = round(end.time - start.time,2)

      ## Define imputation method list
      imputation = list(method = "tkNN",
                        n.nearest.neighbours = ceiling(nrow(cnt)*0.05),
                        processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))

      #########################################################################################

      } else if (tolower(method) %in% c("bpca", "bpca-pcamethods")) {

        start.time = Sys.time()

        PC.estimation = estimate.PCs(mat = t(cnt), method = "bpca", nPcs = pcaMethods.nPCs.to.test)
        imputed.cnt = (pcaMethods::pca(object = t(cnt), method = "bpca", nPcs = PC.estimation$optimal.nPcs, verbose = verbose))@completeObs

        end.time = Sys.time()
        time.taken = round(end.time - start.time,2)

        ## Define imputation method list
        imputation = list(method = "BPCA",
                          PC.estimation = PC.estimation,
                          processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))


        #########################################################################################

      } else if (tolower(method) %in% c("ppca", "ppca-pcamethods")) {

        start.time = Sys.time()

        PC.estimation = estimate.PCs(mat = t(cnt), method = "ppca", nPcs = pcaMethods.nPCs.to.test)
        imputed.cnt = (pcaMethods::pca(object = t(cnt), method = "ppca", nPcs = PC.estimation$optimal.nPcs, verbose = verbose))@completeObs

        end.time = Sys.time()
        time.taken = round(end.time - start.time,2)

        ## Define imputation method list
        imputation = list(method = "PPCA",
                          PC.estimation = PC.estimation,
                          processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))

        #########################################################################################

      } else if (tolower(method) %in% c("regimpute-dreamai", "regimpute")) {

        start.time = Sys.time()

        imputed.cnt = t(impute.RegImpute(data = cnt, fillmethod = RegImpute.fillmethod, maxiter_RegImpute = RegImpute.max.iterations, conv_nrmse = 1e-6))

        end.time = Sys.time()
        time.taken = round(end.time - start.time,2)

        ## Define imputation method list
        imputation = list(method = "RegImpute",
                          parameters = list(fillmethod = RegImpute.fillmethod,
                                            maxiter_RegImpute = RegImpute.max.iterations,
                                            conv_nrmse = 1e-6),
                          processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))

        #########################################################################################

      } else if (tolower(method) == "corknn") {

        start.time = Sys.time()

        imputed.cnt = t(suppressWarnings(imputeKNN(as.matrix(cnt), k = ceiling(nrow(cnt)*0.05) + 1, distance = "correlation", rm.na = TRUE, rm.nan = FALSE, rm.inf = FALSE)))

        end.time = Sys.time()
        time.taken = round(end.time - start.time,2)

        ## Define imputation method list
        imputation = list(method = "corkNN",
                          n.nearest.neighbours = ceiling(nrow(cnt)*0.05),
                          processing.time = paste(gsub("Time difference of ", "",as.character(time.taken)), attributes(time.taken)$units))
      }


    ##########################################################################################



    ### Re-plot distributions
    # melt counts table
    melt.cnt =
      suppressMessages(reshape2::melt(as.data.frame(t(imputed.cnt)))) %>%
      dplyr::mutate(variable = factor(variable, levels = colnames(t(imputed.cnt))))

    # compute stats
    cnt.stats =
      melt.cnt %>%
      dplyr::group_by(variable) %>%
      dplyr::summarise(min = min(value, na.rm = TRUE),
                       max = max(value, na.rm = TRUE))

    boxplot =
      ggplot() +
      geom_violin(data = melt.cnt,
                  mapping = aes(x = variable,
                                y = value,
                                group = variable),
                  width = 0.75,
                  alpha = 0.75,
                  fill = "forestgreen",
                  color = NA) +
      geom_boxplot(data = melt.cnt,
                   mapping = aes(x = variable,
                                 y = value,
                                 group = variable),
                   fill = "white",
                   color = "darkgreen",
                   width = 0.15,
                   outlier.color = "black",
                   outlier.stroke = NA,
                   outlier.size = 2,
                   outlier.alpha = 0.25) +
      geom_line(data = data.frame(cnt.stats),
                mapping = aes(x = variable,
                              y = max,
                              group = 1),
                color = "indianred",
                linetype = 2,
                inherit.aes = F) +
      geom_line(data = data.frame(cnt.stats),
                mapping = aes(x = variable,
                              y = min,
                              group = 1),
                color = "steelblue",
                linetype = 2,
                inherit.aes = F) +
      ylab(ifelse(is.null(DEprot.object@log.base),
                  yes = "Intensity",
                  no = paste0(ifelse(DEprot.object@log.base == exp(1),
                                     yes = "ln", no = paste0("log~",DEprot.object@log.base,"~")),
                              "(Intensity)"))) +
      ggtitle(label = "**Imputed data**", subtitle = "*missForest*") +
      xlab("Sample") +
      theme_classic() +
      theme(axis.text.y = element_text(color = "black"),
            axis.text.x = element_text(color = "black", hjust = 1, angle = 30),
            axis.title = ggtext::element_markdown(color = "black"),
            axis.ticks.y = element_line(color = "black"),
            axis.ticks.x = element_blank(),
            plot.title = ggtext::element_markdown(hjust = 0.5),
            plot.subtitle = ggtext::element_markdown(hjust = 0.5),
            aspect.ratio = 10/ncol(t(imputed.cnt)))


    ### Update object with new counts, imputation method and boxplot
    DEprot.object@imputed = TRUE
    DEprot.object@imputation = imputation
    DEprot.object@imputed.counts = t(imputed.cnt)
    DEprot.object@boxplot.imputed = boxplot


    ### Return updated object
    return(DEprot.object)

  } # END function
