#' @title compare.imp.methods
#'
#' @description Function that computes the Root Mean Squared Error (RMSE) for all the 4 possibile imputation algorithms: \href{https://www.rdocumentation.org/packages/missForest/}{missForest}, \href{https://rdrr.io/cran/VIM/man/kNN.html}{kNN}, \href{https://rdrr.io/bioc/pcaMethods/man/llsImpute.html}{LLS}, \href{https://rdrr.io/bioc/pcaMethods/man/pca.html}{SVD}.
#' A new dataset containing only proteins with known values is created, a certain percentage of NAs is then manually introduced (with the possibility to respect the "pattern" of the missing values). This percentage is equivalent to the percentage of missing values in the original data set. At the end the imputed values in the new data set are compared with the measured (expected) ones.
#'
#' @param DEprot.object A \code{DEprot object}, as generated by \link{load.counts} or \link{load.counts2}.
#' @param percentage.test Numeric value between 0 (excluded) and 100 indicating the percentage of proteins to use for the test dataset. Default: \code{30}.
#' @param correlation.method String indicating the method to use for the correlations. One among: 'pearson', 'spearman'. Default: \code{"pearson"}.
#' @param sample.group.column String indicating the ID of any column of the metadata table. This will be used to introduce the same frequencies of n-missing values for a protein and therefore not introducing the NAs completely at random in the dataset. Default: \code{NULL}, NAs are assigned randomly (same percentage of NAs present in the original table).
#' @param use.normalized.data Logical value indicating whether the imputation should be performed based on the rationalized data. Default: \code{TRUE}.
#' @param run.missForest Logical values indicating whether the test for the \code{missForest} imputation should be performed. Default: \code{TRUE}.
#' @param run.kNN Logical values indicating whether the test for the \code{kNN} imputation method should be performed. Default: \code{TRUE}.
#' @param run.corkNN Logical values indicating whether the test for the \code{corkNN} imputation method should be performed. Default: \code{TRUE}.
#' @param run.tkNN Logical values indicating whether the test for the \code{tkNN} imputation method should be performed. Default: \code{TRUE}.
#' @param run.LLS Logical values indicating whether the test for the \code{LLS} imputation method should be performed. Default: \code{TRUE}.
#' @param run.SVD Logical values indicating whether the test for the \code{SVD} imputation method should be performed. Default: \code{TRUE}.
#' @param run.BPCA Logical values indicating whether the test for the \code{BPCA} imputation method should be performed. Default: \code{TRUE}.
#' @param run.PPCA Logical values indicating whether the test for the \code{PPCA} imputation method should be performed. Default: \code{TRUE}.
#' @param run.RegImpute Logical values indicating whether the test for the \code{RegImpute} imputation method should be performed. Default: \code{TRUE}.
#' @param missForest.max.iterations Max number of iterations for the \code{missForest} algorithm. Default: \code{100}.
#' @param missForest.variable.wise.OOBerror Logical value to define whether the OOB error is returned for each variable separately. Default: \code{TRUE}.
#' @param missForest.cores Number of cores used to run the \code{missForest} algorithm. If \code{missForest.cores} is 1 (or lower), the imputation will be run in parallel. Two modes are possible and can be defined by the parameter \code{missForest.parallel.mode}. Default: \code{1}.
#' @param missForest.parallel.mode Define the mode to use for the parallelization, ignored when \code{cores} is more than 1. One among: 'variables', 'forests'. Default: \code{"variables"}. See also the documentation of the \href{https://www.rdocumentation.org/packages/missForest/versions/1.5/topics/missForest}{missForest function}.
#' @param kNN.n.nearest.neighbours Numeric value indicating the number of nearest neighbors to use to perform the \code{kNN} imputation. Default: \code{10}.
#' @param LLS.k Cluster size, this is the number of similar genes used for regression. Default: \code{2}.
#' @param pcaMethods.nPCs.to.test Numeric value indicating the number of Principal Components to test in order to find the optimal number of PCs to used in the imputation methods from the \code{pcaMethods} package. This includes: 'LLS', 'SVD' (a.k.a 'svdImpute'), 'BPCA-pcaMethods', and 'PPCA'. Default: \code{5}.
#' @param RegImpute.max.iterations Numeric value indicating the number of maximum iteration for the imputation with \code{RegImpute} (from \code{DreamAI}). Default: \code{10}.
#' @param RegImpute.fillmethod String identifying the fill method to be used in the \code{RegImpute} method (from\code{DreamAI}). One among \code{"row_mean"} and \code{"zeros"}. Default: \code{"row_mean"}. It throws an warning if \code{"row_median"} is used.
#' @param normalize.color.bar Logical value indicating whether the color bar limits for the residuals in the correlation plots should be normalized among the methods. Default: \code{TRUE}, the residual color bar absolute maximum is set to the max of all the residuals identified in all the methods,
#' @param low.residual.color String indicating any R-supported color that must be used for the negative values of the residuals color bar in the correlation plots. Default: \code{"firebrick"}.
#' @param zero.residual.color String indicating any R-supported color that must be used for the null residuals (zero, mid gradient color) color bar in the correlation plots. Default: \code{"white"}.
#' @param high.residual.color String indicating any R-supported color that must be used for the positive values of the residuals color bar in the correlation plots. Default: \code{"steelblue4"}.
#' @param verbose Logical valued indicating whether processing messages should be printed. Default: \code{FALSE}.
#' @param seed Numeric value indicating the seed to use for the randomization. Default: \code{NULL}, automatically generated (saved in the \code{seed} slot in the final object).
#'
#' @seealso \href{https://www.rdocumentation.org/packages/missForest/}{missForest}, \href{https://cran.r-project.org/web/packages/VIM/index.html}{VIM}, \href{https://www.bioconductor.org/packages/release/bioc/html/pcaMethods.html}{pcaMethods} R-packages.
#'
#' @return A \code{DEprot.RMSE} object.
#'
#' @import dplyr
#' @import ggplot2
#' @importFrom purrr pmap
#' @importFrom ggpubr stat_cor theme_pubr
#' @importFrom ggridges geom_density_ridges
#' @importFrom stats cor.test glm runif
#' @importFrom lubridate as.duration
#'
#' @examples
#' comparison <- compare.imp.methods(DEprot.object = DEprot::test.toolbox$dpo.norm,
#'                                   percentage.test = 100,
#'                                   sample.group.column = "combined.id",
#'                                   missForest.cores = 1)
#'
#' summary(comparison)
#'
#' comparison
#'
#' @export compare.imp.methods

compare.imp.methods =
  function(DEprot.object,
           percentage.test = 30,
           correlation.method = "pearson",
           sample.group.column = NULL,
           use.normalized.data = TRUE,
           run.missForest = TRUE,
           run.kNN = TRUE,
           run.tkNN = TRUE,
           run.corkNN = TRUE,
           run.LLS = TRUE,
           run.SVD = TRUE,
           run.BPCA = TRUE,
           run.PPCA = TRUE,
           run.RegImpute = TRUE,
           missForest.max.iterations = 100,
           missForest.variable.wise.OOBerror = TRUE,
           missForest.cores = 1,
           missForest.parallel.mode = "variables",
           kNN.n.nearest.neighbours = 10,
           LLS.k = 2,
           pcaMethods.nPCs.to.test = 5,
           RegImpute.max.iterations = 10,
           RegImpute.fillmethod = "row_mean",
           normalize.color.bar = TRUE,
           low.residual.color = "firebrick",
           zero.residual.color = "white",
           high.residual.color = "steelblue4",
           seed = NULL,
           verbose = FALSE) {

    # ### libraries
    # require(dplyr)
    # require(ggplot2)


    ### Check that at least one imputation is running
    if (all(c(run.missForest, run.kNN, run.LLS, run.SVD, run.tkNN, run.BPCA, run.PPCA, run.RegImpute) == FALSE)) {
      stop("At leats on of the imputation methods should be applied: verify the `run.[method]` parameters, and set at least one equal to TRUE.")
      #return(DEprot.object)
    }

    ### check object
    if (!("DEprot" %in% class(DEprot.object))) {
      stop("The input must be an object of class 'DEprot'.")
      #return(DEprot.object)
    }

    ### check percentage value
    if (percentage.test <= 0) {
      stop("The `percentage.test` must be a number above 0.")
      #return(DEprot.object)
    } else if (percentage.test > 100) {
      percentage.test = 100
      warning("The `percentage.test` must be a number at maximum equal to 100.\nThe `percentage.test` value has been set to 100.")
    }


    ### Check if normalized data are available
    if (use.normalized.data == TRUE) {
      if (is.null(DEprot.object@norm.counts)) {
        stop(paste0("You asked to use normalized data for the imputation, but normalized data are not available.\n",
                    "       To perform imputation on raw data, set 'use.normalized.data = FALSE'."))
        #return(DEprot.object)
      } else {
        cnt = DEprot.object@norm.counts
      }
    } else {
      cnt = DEprot.object@raw.counts
    }



    ### Check sample.group.column
    if (!is.null(sample.group.column)) {
      if (sample.group.column == "column.id") {
        sample.group.column = NULL
      } else if (!(sample.group.column %in% colnames(DEprot.object@metadata))) {
        stop(paste0("The `sample.group.column` indicated is not available in the metadata table.\n",
                    "       Columns available: ", paste0(colnames(DEprot.object@metadata), collapse = ", ")))
        #return(DEprot.object)
      } else {
        sample.groups = unique(DEprot.object@metadata[,sample.group.column])
      }
    }




    ### Set seed
    if (is.null(seed)) {
      seed = runif(n = 1, min = 0, max = 2^31-1)
      set.seed(I(seed))
    } else {
      set.seed(I(seed))
    }


    # ---------------------- INTRODUCING NAs --------------------- #
    ### Number of proteins for test
    n.test.prot = min(c(ceiling(nrow(cnt) * (percentage.test/100)), nrow(cnt)))

    ### Get the counts of only known data
    cnt.known = cnt[rowSums(is.na(cnt)) == 0,]

    ### Get the sample data set
    if (n.test.prot < nrow(cnt.known)) {
      sample.data = cnt.known[sample(x = 1:nrow(cnt.known), size = n.test.prot),]
    } else {
      warning("The number of usable proteins is lower than the number of proteins requested.")
      sample.data = cnt.known
    }

    if (nrow(sample.data) == 0) {
      stop("There are not enough proteins that do not contain NAs. Test dataset cannot be created.")
      #return()
    }


    ######## Just overall missing values ########
    if (is.null(sample.group.column)) {
      if (isTRUE(verbose)) {message("Simulating NAs in the known data subset (random-mode)...")}
      ### Introduce artificial NAs
      # Estimate fraction of missing values in the original data
      fraction.missing = sum(is.na(cnt)) / (ncol(cnt) * nrow(cnt))

      # Define how many new NAs are needed in the sample.data
      n.na = floor((ncol(sample.data) * nrow(sample.data)) * fraction.missing)

      # Define the combination of row x column that will define the cells in which the NAs will be introduced
      cells.na = list(rows = sample(1:nrow(sample.data), size = n.na, replace = TRUE),
                      cols = sample(1:ncol(sample.data), size = n.na, replace = TRUE))

      ###### use the proportions per sample group #####
    } else {
      if (isTRUE(verbose)) {message("Simulating NAs in the known data subset (sample.group-mode)...")}
      # compute the effective percentage of rows of the sample.dataset compared to the initial table
      effective.percentage.test = nrow(sample.data) / nrow(cnt)

      # collect the NAs coordinates
      cells.na = list(rows = c(),
                      cols = c())

      fraction.missing.group = list()

      for (i in 1:length(sample.groups)) {
        # Define missing values per each group and row
        samples.in.group = DEprot.object@metadata[DEprot.object@metadata[, sample.group.column] == sample.groups[i], "column.id"]
        original.col.idx = c(1:ncol(cnt))[colnames(cnt) %in% samples.in.group]
        group.sample.data = cnt[,colnames(cnt) %in% samples.in.group]
        na.count.in.group.per.row = table(rowSums(is.na(group.sample.data)))

        fraction.missing.group[[i]] =
          data.frame(sample.group = sample.groups[i],
                     n.NAs.in.row = as.numeric(names(na.count.in.group.per.row)),
                     n.rows = as.vector(na.count.in.group.per.row)) %>%
          dplyr::mutate(n.tot.NAs = n.NAs.in.row * n.rows) %>%
          dplyr::mutate(fraction.NAs = as.vector(n.tot.NAs/nrow(cnt)))

        cells.na.rows.group = c()
        cells.na.cols.group = c()

        if (length(na.count.in.group.per.row) > 1) {
          for (j in 2:length(na.count.in.group.per.row)){
            n.rows = max(1, floor(na.count.in.group.per.row[j] * effective.percentage.test))
            cells.na.rows.group.j = sample(c(1:nrow(sample.data))[!(c(1:nrow(sample.data)) %in% unique(cells.na.rows.group))], size = n.rows, replace = FALSE)
            cells.na.rows.group = c(cells.na.rows.group, rep(cells.na.rows.group.j, each = j-1))
            cells.na.cols.group = c(cells.na.cols.group, sapply(1:n.rows, function(x){sample(original.col.idx, size = j-1, replace = FALSE)}, USE.NAMES = FALSE))
          }
        }

        cells.na = list(rows = c(cells.na$rows, cells.na.rows.group),
                        cols = c(cells.na$cols, cells.na.cols.group))
      }

      fraction.missing = do.call(rbind, fraction.missing.group)
    }


    # convert coordinates to IDs
    cells.na = list(rows = rownames(sample.data)[cells.na$rows],
                    cols = colnames(sample.data)[cells.na$cols])

    # Add NAs to the sample.data table
    sample.data.na = sample.data
    for (i in 1:length(cells.na$rows)) {sample.data.na[cells.na$rows[i], cells.na$cols[i]] = NA}



    ### missForest method is made on variation of the data, so it cannot handle any row that does not have enough variance
    # therefore all the rows with less than 3 values available will be removed
    if (run.missForest == TRUE) {
      nas.per.row.test.tb = rowSums(!is.na(sample.data.na))
      idx.rows.to.keep = rownames(sample.data.na)[as.vector(which(nas.per.row.test.tb > 2))]

      sample.data.na.filter.var = sample.data.na[idx.rows.to.keep, ]

      if (nrow(sample.data.na.filter.var) == 0) {
        warning("The `missForest` imputation cannot be run: there is not enough variability in the data. Imputation method skipped.")
        run.missForest = FALSE
      } else {
        sample.data.na = sample.data.na.filter.var
        sample.data = sample.data[idx.rows.to.keep, ]

        cells.na = list(rows = cells.na$rows[cells.na$rows %in% idx.rows.to.keep],
                        cols = cells.na$cols[cells.na$rows %in% idx.rows.to.keep])
      }
    }


    if (nrow(sample.data) == 0) {
      stop("There are not enough proteins that do not contain NAs. Test dataset cannot be created.")
      #return()
    }


    ### Generate a new dpo object with the reduced and artificially modified data
    dpo.na = DEprot::load.counts2(counts = sample.data.na,
                                  metadata = DEprot.object@metadata,
                                  data.type = "normalized",
                                  log.base = DEprot.object@log.base)


    ### Run all the imputations on the sample.data
    if (run.missForest == TRUE) {
      if (isTRUE(verbose)) {message("Performing `missForest` imputation...")}
      dpo.na_missForest = DEprot::impute.counts(DEprot.object = dpo.na,
                                                method = "missForest",
                                                missForest.max.iterations = missForest.max.iterations,
                                                missForest.variable.wise.OOBerror = missForest.variable.wise.OOBerror,
                                                missForest.cores = missForest.cores,
                                                missForest.parallel.mode = missForest.parallel.mode,
                                                verbose = verbose,
                                                seed = seed)

      missForest = dpo.na_missForest@imputed.counts
    } else {
      dpo.na_missForest = NULL
      missForest = NULL
    }



    if (run.kNN == TRUE) {
      if (isTRUE(verbose)) {message("Performing `kNN` imputation...")}
      dpo.na_kNN = DEprot::impute.counts(DEprot.object = dpo.na,
                                         method = "kNN",
                                         kNN.n.nearest.neighbours = kNN.n.nearest.neighbours,
                                         verbose = verbose,
                                         seed = seed)
      kNN = dpo.na_kNN@imputed.counts
    } else {
      dpo.na_kNN = NULL
      kNN = NULL
    }



    if (run.LLS == TRUE) {
      if (isTRUE(verbose)) {message("Performing `LLS` imputation...")}
      dpo.na_LLS = DEprot::impute.counts(DEprot.object = dpo.na,
                                         method = "LLS",
                                         LLS.k = LLS.k,
                                         verbose = verbose,
                                         seed = seed)
      LLS = dpo.na_LLS@imputed.counts
    } else {
      dpo.na_LLS = NULL
      LLS = NULL
    }


    if (run.SVD == TRUE) {
      if (isTRUE(verbose)) {message("Performing `SVD` imputation...")}
      dpo.na_SVD = DEprot::impute.counts(DEprot.object = dpo.na,
                                         method = "SVD",
                                         pcaMethods.nPCs.to.test = pcaMethods.nPCs.to.test,
                                         verbose = verbose,
                                         seed = seed)
      SVD = dpo.na_SVD@imputed.counts
    } else {
      dpo.na_SVD = NULL
      SVD = NULL
    }



    if (run.BPCA == TRUE) {
      if (isTRUE(verbose)) {message("Performing `BPCA` imputation...")}
      dpo.na_BPCA = DEprot::impute.counts(DEprot.object = dpo.na,
                                          method = "BPCA",
                                          pcaMethods.nPCs.to.test = pcaMethods.nPCs.to.test,
                                          verbose = verbose,
                                          seed = seed)
      BPCA = dpo.na_BPCA@imputed.counts
    } else {
      dpo.na_BPCA = NULL
      BPCA = NULL
    }


    if (run.PPCA == TRUE) {
      if (isTRUE(verbose)) {message("Performing `PPCA` imputation...")}
      dpo.na_PPCA = DEprot::impute.counts(DEprot.object = dpo.na,
                                          method = "PPCA",
                                          pcaMethods.nPCs.to.test = pcaMethods.nPCs.to.test,
                                          verbose = verbose,
                                          seed = seed)
      PPCA = dpo.na_PPCA@imputed.counts
    } else {
      dpo.na_PPCA = NULL
      PPCA = NULL
    }



    if (run.RegImpute == TRUE) {
      if (isTRUE(verbose)) {message("Performing `RegImpute` imputation...")}
      dpo.na_RegImpute = DEprot::impute.counts(DEprot.object = dpo.na,
                                               method = "RegImpute",
                                               RegImpute.max.iterations = RegImpute.max.iterations,
                                               RegImpute.fillmethod = RegImpute.fillmethod,
                                               verbose = verbose,
                                               seed = seed)
      RegImpute = dpo.na_RegImpute@imputed.counts
    } else {
      dpo.na_RegImpute = NULL
      RegImpute = NULL
    }



    if (run.tkNN == TRUE) {
      if (isTRUE(verbose)) {message("Performing `tkNN` imputation...")}
      dpo.na_tkNN = DEprot::impute.counts(DEprot.object = dpo.na,
                                          method = "tkNN",
                                          verbose = verbose,
                                          seed = seed)
      tkNN = dpo.na_tkNN@imputed.counts
    } else {
      dpo.na_tkNN = NULL
      tkNN = NULL
    }



    if (run.corkNN == TRUE) {
      if (isTRUE(verbose)) {message("Performing `corkNN` imputation...")}
      dpo.na_corkNN = DEprot::impute.counts(DEprot.object = dpo.na,
                                          method = "corkNN",
                                          verbose = verbose,
                                          seed = seed)
      corkNN = dpo.na_corkNN@imputed.counts
    } else {
      dpo.na_corkNN = NULL
      corkNN = NULL
    }






    ### Collect all the imputed tables in a list
    imp.tables = list(missForest = missForest,
                      kNN = kNN,
                      tkNN = tkNN,
                      corkNN = corkNN,
                      LLS = LLS,
                      SVD = SVD,
                      BPCA = BPCA,
                      PPCA = PPCA,
                      RegImpute = RegImpute)

    imputed.objects = list(missForest = dpo.na_missForest,
                           kNN = dpo.na_kNN,
                           tkNN = dpo.na_tkNN,
                           corkNN = dpo.na_corkNN,
                           LLS = dpo.na_LLS,
                           SVD = dpo.na_SVD,
                           BPCA = dpo.na_BPCA,
                           PPCA = dpo.na_PPCA,
                           RegImpute = dpo.na_RegImpute)

    # Remove null elements from the lists of tables and results
    if (FALSE %in% c(run.missForest, run.kNN, run.LLS, run.SVD, run.tkNN, run.BPCA, run.PPCA, run.RegImpute)) {
      imp.tables = imp.tables[as.vector(!sapply(imp.tables, is.null))]
      imputed.objects = imputed.objects[as.vector(!sapply(imputed.objects, is.null))]
    }



    ### Computation of the Root Mean Squared Error (RMSE)
    # RMSE = sqrt[ Σ(Pi – Oi)² / n ]
    # where: Pi is the predicted/imputed value for the i-th observation; Oi is the observed/real value for the i-th observation; n is the number of observations.
    # 1. Calculate the residuals: For each data point, subtract the predicted value from the observed value. This difference is the residual.
    # 2. Square the residuals: Square each of the residuals calculated in the previous step.
    # 3. Calculate the mean of the squared residuals: Sum all the squared residuals and divide by the number of data points (n). This is the Mean Squared Error (MSE).
    # 4. Take the square root: Finally, calculate the square root of the MSE. This result is the RMSE.


    # get the 'expected' values
    exp.values = c()
    for (i in 1:length(cells.na$rows)) {exp.values[i] = sample.data[cells.na$rows[i], cells.na$cols[i]]}

    exp.tb = data.frame(#row.idx = which(rownames(sample.data) %in% cells.na$rows),
      #col.idx = which(colnames(sample.data) %in% cells.na$cols),
      row.id = cells.na$rows,
      col.id = cells.na$cols,
      expected.values = exp.values)


    # compute RMSE scores
    RMSE.tables = list()
    RMSE.scores = c()
    cor.coeff = c()

    for (i in 1:length(imp.tables)) {
      imputed.values = c()
      for (k in 1:length(cells.na$rows)) {imputed.values[k] = imp.tables[[i]][cells.na$rows[k], cells.na$cols[k]]}

      RMSE.tables[[i]] =
        exp.tb %>%
        dplyr::mutate(imputation.method = names(imp.tables)[i],
                      imputed.values = imputed.values) %>%
        dplyr::mutate(residuals = imputed.values - expected.values) %>%
        dplyr::mutate(sq.residuals = residuals ^ 2)

      MSE_mean.sq.residuals = mean(sqrt(RMSE.tables[[i]]$sq.residuals), na.rm = T)
      RMSE.scores[i] = sqrt(MSE_mean.sq.residuals)
      cor.coeff[i] = suppressWarnings(unname((cor.test(x = RMSE.tables[[i]]$expected.values, y = RMSE.tables[[i]]$imputed.values, method = tolower(correlation.method)))$estimate))
    }

    names(RMSE.tables) = names(imp.tables)
    names(RMSE.scores) = names(imp.tables)
    names(cor.coeff) = names(imp.tables)


    ## Collect computation time
    comp.time = c()

    for (i in 1:length(imputed.objects)) {
      comp.time[i] = lubridate::as.duration(imputed.objects[[i]]@imputation$processing.time)
    }




    ## Make a table for RMSE and correlation, and rank
    RMSE.scores.tb =
      data.frame(imputation.method = names(RMSE.scores),
                 RMSE = RMSE.scores,
                 correlation.coeff = cor.coeff,
                 processing.time = comp.time) %>%
      dplyr::arrange(RMSE, desc(correlation.coeff), processing.time) %>%
      dplyr::mutate(rank = 1:length(RMSE.scores))


    ### Plot correlations
    correlations = list()
    max.residual = c()

    for (i in 1:length(RMSE.tables)) {
      max.residual = c(max.residual, max(abs(RMSE.tables[[i]]$residuals)))

      correlations[[i]] =
        ggplot(data = RMSE.tables[[i]],
               aes(x = expected.values,
                   y = imputed.values)) +
        geom_abline(slope = 1, intercept = 0, linetype = "dotted", color = "gray50") +
        geom_point(aes(fill = residuals), color = "black", size = 2.5, alpha = 0.75, shape = 21) +
        geom_smooth(formula = y ~ x, method = "glm", fill = "steelblue") +
        ggpubr::stat_cor(mapping = aes(group = 1), r.digits = 3, method = tolower(correlation.method), cor.coef.name = ifelse(test = tolower(correlation.method) == "pearson", yes = "R", no = "rho")) +
        ggtitle(paste0("**",names(RMSE.tables)[i],"**")) +
        ylab("Imputed values") +
        xlab("Expected values") +
        annotate(geom = "text", x = +Inf, y = -Inf, label = paste0("RMSE = ", round(RMSE.scores[i],3)), hjust = 1.25, vjust = -1.5) +
        ggpubr::theme_pubr(legend = "right") +
        theme(plot.title = ggtext::element_markdown(hjust = 0.5),
              aspect.ratio = 1)
    }


    ## apply the same color bar to all the plots
    if (normalize.color.bar == TRUE) {
      correlations = lapply(correlations,
                            function(x){x + scale_fill_gradient2(low = low.residual.color,
                                                                 mid = zero.residual.color,
                                                                 high = high.residual.color,
                                                                 midpoint = 0,
                                                                 name = "Residual\n[imp - exp]",
                                                                 limits = c(-1,1)*max(abs(max.residual)))})
    } else {
      correlations = purrr::pmap(.l = list(plot = correlations,
                                           res.max = max.residual),
                                 .f = function(plot,res.max){
                                   plot + scale_fill_gradient2(low = low.residual.color,
                                                               mid = zero.residual.color,
                                                               high = high.residual.color,
                                                               midpoint = 0,
                                                               name = "Residual\n[imp - exp]",
                                                               limits = c(-1,1)*max(abs(res.max)))
                                 },
                                 .progress = FALSE)
    }

    names(correlations) = names(imp.tables)




    ### Plot residuals distribution
    method.colors = c("kNN" = "indianred4",
                      "tKNN" = "indianred1",
                      "corkNN" = "pink",
                      "LLS" = "#75cab0",
                      "missForest" = "steelblue",
                      "SVD" = "#d693ff",
                      "BPCA" = "orange",
                      "PPCA" = "chartreuse2",
                      "RegImpute" = "lightgoldenrod3")

    density.residuals =
      ggplot(data = do.call(rbind, RMSE.tables),
             aes(x = residuals,
                 y = imputation.method,
                 fill = imputation.method,
                 color = imputation.method)) +
      ggridges::geom_density_ridges(alpha = 0.3) +
      scale_fill_manual(values = method.colors, name = "Imputation\nmethod") +
      scale_color_manual(values = method.colors, name = "Imputation\nmethod") +
      ylab(NULL) +
      xlab("Residuals") +
      xlim(c(-1,1)*max(abs(do.call(rbind, RMSE.tables)$residuals))) +
      ggpubr::theme_pubr(legend = "right") +
      theme(aspect.ratio = 1,
            axis.ticks.y = element_blank())




    ### Make and return DEprot.RMSE object
    DEprot.RMSE.object =
      new(Class = "DEprot.RMSE",
          original.DEprot.object = DEprot.object,
          percentage.test = percentage.test,
          seed = seed,
          fraction.missing.values = fraction.missing,
          test.dataset = sample.data,
          imputed.objects = imputed.objects,
          RMSE.tables = RMSE.tables,
          RMSE.scores = RMSE.scores.tb,
          correlation.plots = correlations,
          density.residuals = density.residuals)

    return(DEprot.RMSE.object)

  } # END function
